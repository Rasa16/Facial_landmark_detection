{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"face_landmark_extraction.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1WcUS01sJ4Qsoqx8v9HRf3ZgwdBnSAluV","authorship_tag":"ABX9TyPUGvt8/Wig0/i/8394ycHL"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"WeLba2tp7DLQ","colab_type":"code","colab":{}},"source":["# import the necessary packages\n","from imutils import face_utils\n","import numpy as np\n","import argparse\n","import imutils\n","import dlib\n","import cv2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QAdgR4WI7Pff","colab_type":"code","colab":{}},"source":["def visualize_facial_landmarks(image, shape, colors=None, alpha=0.75):\n","\t# create two copies of the input image -- one for the\n","\t# overlay and one for the final output image\n","\toverlay = image.copy()\n","\toutput = image.copy()\n","\t# if the colors list is None, initialize it with a unique\n","\t# color for each facial landmark region\n","\tif colors is None:\n","\t\tcolors = [(19, 199, 109), (79, 76, 240), (230, 159, 23),\n","\t\t\t(168, 100, 168), (158, 163, 32),\n","\t\t\t(163, 38, 32), (180, 42, 220)]\n","\n","  \t# loop over the facial landmark regions individually\n","\tfor (i, name) in enumerate(FACIAL_LANDMARKS_IDXS.keys()):\n","\t\t# grab the (x, y)-coordinates associated with the\n","\t\t# face landmark\n","\t\t(j, k) = FACIAL_LANDMARKS_IDXS[name]\n","\t\tpts = shape[j:k]\n","\t\t# check if are supposed to draw the jawline\n","\t\tif name == \"jaw\":\n","\t\t\t# since the jawline is a non-enclosed facial region,\n","\t\t\t# just draw lines between the (x, y)-coordinates\n","\t\t\tfor l in range(1, len(pts)):\n","\t\t\t\tptA = tuple(pts[l - 1])\n","\t\t\t\tptB = tuple(pts[l])\n","\t\t\t\tcv2.line(overlay, ptA, ptB, colors[i], 2)\n","\t\t# otherwise, compute the convex hull of the facial\n","\t\t# landmark coordinates points and display it\n","\t\telse:\n","\t\t\thull = cv2.convexHull(pts)\n","\t\t\tcv2.drawContours(overlay, [hull], -1, colors[i], -1)\n","  \t# apply the transparent overlay\n","\tcv2.addWeighted(overlay, alpha, output, 1 - alpha, 0, output)\n","\t# return the output image\n","\treturn output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q5L-2Fer8ATX","colab_type":"code","colab":{}},"source":["# initialize dlib's face detector (HOG-based) and then create\n","# the facial landmark predictor\n","detector = dlib.get_frontal_face_detector()\n","predictor = dlib.shape_predictor('/content/drive/My Drive/DEEP LEARNING/face landmark detection/facial-landmarks/shape_predictor_68_face_landmarks.dat')\n","# load the input image, resize it, and convert it to grayscale\n","image = cv2.imread('/content/drive/My Drive/DEEP LEARNING/IMG_20191028_095653_206.jpg')\n","image = imutils.resize(image, width=500)\n","gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","# detect faces in the grayscale image\n","rects = detector(gray, 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jnf1eaqV_zKE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1kBnhSb2sY5ga2wWIMYBvz3hPCxPnqqpx"},"outputId":"c6353d92-1ac2-43c1-a862-6158b09e837b","executionInfo":{"status":"error","timestamp":1588853029431,"user_tz":-330,"elapsed":10041,"user":{"displayName":"Rahul Sahni","photoUrl":"","userId":"02406577186469285098"}}},"source":["from google.colab.patches import cv2_imshow\n","\n","# loop over the face detections\n","for (i, rect) in enumerate(rects):\n","\t# determine the facial landmarks for the face region, then\n","\t# convert the landmark (x, y)-coordinates to a NumPy array\n","\tshape = predictor(gray, rect)\n","\tshape = face_utils.shape_to_np(shape)\n","\t# loop over the face parts individually\n","\tfor (name, (i, j)) in face_utils.FACIAL_LANDMARKS_IDXS.items():\n","\t\t# clone the original image so we can draw on it, then\n","\t\t# display the name of the face part on the image\n","\t\tclone = image.copy()\n","\t\tcv2.putText(clone, name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n","\t\t\t0.7, (0, 0, 255), 2)\n","\t\t# loop over the subset of facial landmarks, drawing the\n","\t\t# specific face part\n","\t\tfor (x, y) in shape[i:j]:\n","\t\t\tcv2.circle(clone, (x, y), 1, (0, 0, 255), -1)\n","   \n","  \t\t# extract the ROI of the face region as a separate image\n","\t\t(x, y, w, h) = cv2.boundingRect(np.array([shape[i:j]]))\n","\t\troi = image[y:y + h, x:x + w]\n","\t\troi = imutils.resize(roi, width=250, inter=cv2.INTER_CUBIC)\n","\t\t# show the particular face part\n","\t\tcv2_imshow( roi)\n","\t\tcv2_imshow(clone)\n","\t\tcv2.waitKey(0)\n","\t# visualize all facial landmarks with a transparent overlay\n","\toutput = face_utils.visualize_facial_landmarks(image, shape)\n","\tcv2_imshow( output)\n","\tcv2.waitKey(0)"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"NELhIQHYADjr","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}